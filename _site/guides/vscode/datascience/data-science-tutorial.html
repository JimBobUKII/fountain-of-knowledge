<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Data Science in VS Code tutorial | Fountain of Knowledge </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Data Science in VS Code tutorial | Fountain of Knowledge ">
    <meta name="generator" content="docfx 2.57.2.0">
    
    <link rel="shortcut icon" href="../../../favicon.ico">
    <link rel="stylesheet" href="../../../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../../../styles/docfx.css">
    <link rel="stylesheet" href="../../../styles/main.css">
    <meta property="docfx:navrel" content="../../../toc.html">
    <meta property="docfx:tocrel" content="../../toc.html">
    
    <meta property="docfx:rel" content="../../../">
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../../../index.html">
                <img id="logo" class="svg" src="../../../logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div class="container body-content">
        
        <div id="search-results">
          <div class="search-list">Search Results for <span></span></div>
          <div class="sr-items">
            <p><i class="glyphicon glyphicon-refresh index-loading"></i></p>
          </div>
          <ul id="pagination" data-first="First" data-prev="Previous" data-next="Next" data-last="Last"></ul>
        </div>
      </div>
      <div role="main" class="container body-content hide-when-search">
        
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="">
<h1 id="data-science-in-vs-code-tutorial">Data Science in VS Code tutorial</h1>

<p>This tutorial demonstrates using Visual Studio Code and the Microsoft Python extension with common data science libraries to explore a basic data science scenario. Specifically, using passenger data from the Titanic, you will learn how to set up a data science environment, import and clean data, create a machine learning model for predicting survival on the Titanic, and evaluate the accuracy of the generated model.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>The following installations are required for the completion of the tutorial. If you do not have them already, install them prior to beginning.</p>
<ul>
<li><p><a href="https://code.visualstudio.com/">Visual Studio Code</a></p>
</li>
<li><p>The <a href="https://marketplace.visualstudio.com/items?itemName=ms-python.python">Python extension for VS Code</a> and <a href="https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter">Jupyter extension for VS Code</a> from the Visual Studio Marketplace. Note that by default, the Python extension installs the Jupyter extension for you. For additional details on installing extensions, see <a href="/docs/editor/extension-gallery.md">Extension Marketplace</a>. Both extensions are published by Microsoft.</p>
</li>
<li><p><a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda with Python 3.7</a></p>
<blockquote>
<p><strong>Note</strong>: If you already have the full Anaconda distribution installed, you don't need to install Miniconda. Alternatively, if you'd prefer not to use Anaconda or Miniconda, you can create a Python virtual environment and install the packages needed for the tutorial using pip. If you go this route, you will need to install the following packages: pandas, jupyter, seaborn, scikit-learn, keras, and tensorflow.</p>
</blockquote>
</li>
</ul>
<h2 id="set-up-a-data-science-environment">Set up a data science environment</h2>
<p>Visual Studio Code and the Python extension provide a great editor for data science scenarios. With native support for Jupyter notebooks combined with Anaconda, it's easy to get started. In this section, you will create a workspace for the tutorial, create an Anaconda environment with the data science modules needed for the tutorial, and create a Jupyter notebook that you'll use for creating a machine learning model.</p>
<ol>
<li><p>Begin by creating an Anaconda environment for the data science tutorial. Open an Anaconda command prompt and run <code>conda create -n myenv python=3.7 pandas jupyter seaborn scikit-learn keras tensorflow</code> to create an environment named <strong>myenv</strong>. For additional information about creating and managing Anaconda environments, see the <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html">Anaconda documentation</a>.</p>
</li>
<li><p>Next, create a folder in a convenient location to serve as your VS Code workspace for the tutorial, name it <code>hello_ds</code>.</p>
</li>
<li><p>Open the project folder in VS Code by running VS Code and using the <strong>File</strong> &gt; <strong>Open Folder</strong> command. Note that you can safely trust opening the folder, since you created it.</p>
</li>
<li><p>Once VS Code launches, create the Jupyter notebook that will be used for the tutorial. Open the Command Palette (<code>kb(workbench.action.showCommands)</code>) and select <strong>Jupyter: Create New Blank Jupyter Notebook</strong>.</p>
<p><img src="images/data-science-tutorial/create-notebook.png" alt="Creating a new Jupyter Notebook"></p>
<blockquote>
<p><strong>Note</strong>: Alternatively, from the VS Code File Explorer, you can use the New File icon to create a Notebook file named <code>hello.ipynb</code>.</p>
</blockquote>
</li>
<li><p>Save the file as <code>hello.ipynb</code> using <strong>File</strong> &gt; <strong>Save As...</strong>.</p>
</li>
<li><p>After your file is created, you should see the open <a href="https://jupyter.org/">Jupyter notebook</a> in the notebook editor. For additional information about native Jupyter notebook support, you can read the <a href="/docs/datascience/jupyter-notebooks.md">Jupyter Notebooks</a> topic.</p>
<p><img src="images/data-science-tutorial/notebook-editor.png" alt="Viewing a new Jupyter Notebook"></p>
</li>
<li><p>Now select <strong>Select Kernel</strong> at the top right of the notebook.</p>
<p><img src="images/data-science-tutorial/select-kernel.png" alt="Selecting a Jupyter Notebook Kernel"></p>
</li>
<li><p>Choose the Python environment you created above in which to run your kernel.</p>
<p><img src="images/data-science-tutorial/choose-myenv.png" alt="Choose a kernel from created environment"></p>
</li>
</ol>
<h2 id="prepare-the-data">Prepare the data</h2>
<p>This tutorial uses the <a href="https://hbiostat.org/data/repo/titanic.html">Titanic dataset</a> available on <a href="https://www.openml.org/d/40945">OpenML.org</a>, which is obtained from Vanderbilt University's Department of Biostatistics at <a href="https://hbiostat.org/data/">https://hbiostat.org/data</a>. The Titanic data provides information about the survival of passengers on the Titanic, as well as characteristics about the passengers such as age and ticket class. Using this data, the tutorial will establish a model for predicting whether a given passenger would have survived the sinking of the Titanic. This section shows how to load and manipulate data in your Jupyter notebook.</p>
<ol>
<li><p>To begin, download the Titanic data from <a href="https://www.openml.org/d/40945">OpenML.org</a> as a CSV file (download links in the upper right) named <code>data.csv</code> and save it to the <code>hello_ds</code> folder that you created in the previous section.</p>
</li>
<li><p>If you haven't already opened the file in VS Code, open the <code>hello_ds</code> folder and the Jupyter notebook (<code>hello.ipynb</code>), by going to <strong>File</strong> &gt; <strong>Open Folder</strong>.</p>
</li>
<li><p>Within your Jupyter notebook, begin by importing the <a href="https://pandas.pydata.org/">pandas</a> and <a href="https://numpy.org/">numpy</a> libraries, two common libraries used for manipulating data, and loading the Titanic data into a pandas <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html">DataFrame</a>. To do so, copy the code below into the first cell of the notebook. For additional guidance about working with Jupyter notebooks in VS Code, see the <a href="/docs/datascience/jupyter-notebooks.md">Working with Jupyter Notebooks</a> documentation.</p>
<pre><code class="lang-python">import pandas as pd
import numpy as np
data = pd.read_csv('data.csv')
</code></pre>
</li>
<li><p>Now, run the cell using the Run cell icon or the <code>kbstyle(Shift+Enter)</code> shortcut.</p>
<p><img src="images/data-science-tutorial/jupyter-cell-01.png" alt="Running a Jupyter notebook cell"></p>
</li>
<li><p>After the cell finishes running, you can view the data that was loaded using the Variables Explorer and Data Viewer. First select the <strong>Variables</strong> icon in the notebook's upper toolbar.</p>
<p><img src="images/data-science-tutorial/variable-explorer-1.png" alt="Select Variables icon"></p>
</li>
<li><p>A <strong>JUPYTER: VARIABLES</strong> pane will open at the bottom of VS Code. It contains a list of the variables defined so far in your running kernel.</p>
<p><img src="images/data-science-tutorial/variable-explorer-2.png" alt="Variables pane"></p>
</li>
<li><p>To view the data in the Pandas DataFrame just loaded, select the Data Viewer icon to the left of the <code>data</code> variable.</p>
<p><img src="images/data-science-tutorial/variable-explorer-3.png" alt="Select Data Viewer icon"></p>
</li>
<li><p>Use the Data Viewer to view, sort, and filter the rows of data. After reviewing the data, it can then be helpful to graph some aspects of it to help visualize the relationships between the different variables.</p>
<p><img src="images/data-science-tutorial/dataviewer.png" alt="Data viewer and variable explorer"></p>
</li>
<li><p>Before the data can be graphed, you need to make sure that there aren't any issues with it. If you look at the Titanic csv file, one thing you'll notice is that a question mark (&quot;?&quot;) was used to designate cells where data wasn't available.</p>
<p>While Pandas can read this value into a DataFrame, the result for a column like Age is that its data type will be set to Object instead of a numeric data type, which is problematic for graphing.</p>
<p>This problem can be corrected by replacing the question mark with a missing value that pandas is able to understand. Add the following code to the next cell in your notebook to replace the question marks in the <strong>age</strong> and <strong>fare</strong> columns with the <a href="https://docs.scipy.org/doc/numpy/reference/constants.html?highlight=nan#numpy.nan">numpy NaN</a> value. Notice that we also need to update the column's data type after replacing the values.</p>
<blockquote>
<p><strong>Tip</strong>: To add a new cell you can use the insert cell icon that's in the bottom left corner of an existing cell. Alternatively, you can also use the <code>kbstyle(Esc)</code> to enter command mode, followed by the <code>kbstyle(B)</code> key.</p>
</blockquote>
<pre><code class="lang-python">data.replace('?', np.nan, inplace= True)
data = data.astype({&quot;age&quot;: np.float64, &quot;fare&quot;: np.float64})
</code></pre>
<blockquote>
<p><strong>Note</strong>: If you ever need to see the data type that has been used for a column, you can use the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes">DataFrame dtypes</a> attribute.</p>
</blockquote>
</li>
<li><p>Now that the data is in good shape, you can use <a href="https://seaborn.pydata.org/">seaborn</a> and <a href="https://matplotlib.org">matplotlib</a> to view how certain columns of the dataset relate to survivability. Add the following code to the next cell in your notebook and run it to see the generated plots.</p>
<pre><code class="lang-python">import seaborn as sns
import matplotlib.pyplot as plt

fig, axs = plt.subplots(ncols=5, figsize=(30,5))
sns.violinplot(x=&quot;survived&quot;, y=&quot;age&quot;, hue=&quot;sex&quot;, data=data, ax=axs[0])
sns.pointplot(x=&quot;sibsp&quot;, y=&quot;survived&quot;, hue=&quot;sex&quot;, data=data, ax=axs[1])
sns.pointplot(x=&quot;parch&quot;, y=&quot;survived&quot;, hue=&quot;sex&quot;, data=data, ax=axs[2])
sns.pointplot(x=&quot;pclass&quot;, y=&quot;survived&quot;, hue=&quot;sex&quot;, data=data, ax=axs[3])
sns.violinplot(x=&quot;survived&quot;, y=&quot;fare&quot;, hue=&quot;sex&quot;, data=data, ax=axs[4])
</code></pre>
<p><img src="images/data-science-tutorial/jupyter-cell-02.png" alt="Graphing the titanic data"></p>
<p>To better view details on the graphs, you can open them in the plot viewer by hovering over the upper right corner of the graph and clicking the button that appears.</p>
<p><img src="images/data-science-tutorial/plot-viewer.png" alt="Plot Viewer Buttons"></p>
</li>
<li><p>These graphs are helpful in seeing some of the relationships between survival and the input variables of the data, but it's also possible to use <strong>pandas</strong> to calculate correlations. To do so, all the variables used need to be numeric for the correlation calculation and currently gender is stored as a string. To convert those string values to integers, add and run the following code.</p>
<pre><code class="lang-python">data.replace({'male': 1, 'female': 0}, inplace=True)
</code></pre>
</li>
<li><p>Now, you can analyze the correlation between all the input variables to identify the features that would be the best inputs to a machine learning model. The closer a value is to 1, the higher the correlation between the value and the result. Use the following code to correlate the relationship between all variables and survival.</p>
<pre><code class="lang-python">data.corr().abs()[[&quot;survived&quot;]]
</code></pre>
<p><img src="images/data-science-tutorial/jupyter-cell-03.png" alt="Determining the correlation between input variables and survival"></p>
</li>
<li><p>Looking at the correlation results, you'll notice that some variables like gender have a fairly high correlation to survival, while others like relatives (sibsp = siblings or spouse, parch = parents or children) seem to have little correlation.</p>
<p>Let's hypothesize that <strong>sibsp</strong> and <strong>parch</strong> are related in how they affect survivability, and group them into a new column called &quot;relatives&quot; to see whether the combination of them has a higher correlation to survivability. To do this, you will check if for a given passenger, the number of <strong>sibsp</strong> and <strong>parch</strong> is greater than 0 and, if so, you can then say that they had a relative on board.</p>
<p>Use the following code to create a new variable and column in the dataset called <code>relatives</code> and check the correlation again.</p>
<pre><code class="lang-python">data['relatives'] = data.apply (lambda row: int((row['sibsp'] + row['parch']) &gt; 0), axis=1)
data.corr().abs()[[&quot;survived&quot;]]
</code></pre>
<p><img src="images/data-science-tutorial/jupyter-cell-04.png" alt="Determining the correlation between having relatives and survival"></p>
</li>
<li><p>You'll notice that in fact when looked at from the standpoint of whether a person had relatives, versus how many relatives, there is a higher correlation with survival. With this information in hand, you can now drop from the dataset the low value <strong>sibsp</strong> and <strong>parch</strong> columns, as well as any rows that had <strong>NaN</strong> values, to end up with a dataset that can be used for training a model.</p>
<pre><code class="lang-python">data = data[['sex', 'pclass','age','relatives','fare','survived']].dropna()
</code></pre>
<blockquote>
<p><strong>Note</strong>: Although age had a low direct correlation, it was kept because it seems reasonable that it might still have correlation in conjunction with other inputs.</p>
</blockquote>
</li>
</ol>
<h2 id="train-and-evaluate-a-model">Train and evaluate a model</h2>
<p>With the dataset ready, you can now begin creating a model. For this section you'll use the <a href="https://scikit-learn.org/stable/">scikit-learn</a> library (as it offers some useful helper functions) to do pre-processing of the dataset, train a classification model to determine survivability on the Titanic, and then use that model with test data to determine its accuracy.</p>
<ol>
<li><p>A common first step to training a model is to divide up the dataset into training and validation data. This allows you to use a portion of the data to train the model and a portion of the data to test the model. If you used all your data to train the model, you wouldn't have a way to estimate how well it would actually perform against data the model has not yet seen. A benefit of the scikit-learn library is that it provides a method specifically for splitting a dataset into training and test data.</p>
<p>Add and run a cell with the following code to the notebook to split up the data.</p>
<pre><code class="lang-python">from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(data[['sex','pclass','age','relatives','fare']], data.survived, test_size=0.2, random_state=0)
</code></pre>
</li>
<li><p>Next, you'll normalize the inputs such that all features are treated equally. For example, within the dataset the values for age range from ~0-100, while gender is only a 1 or 0. By normalizing all the variables, you can ensure that the ranges of values are all the same. Use the following code in a new code cell to scale the input values.</p>
<pre><code class="lang-python">from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(x_train)
X_test = sc.transform(x_test)
</code></pre>
</li>
<li><p>There are a number of different machine learning algorithms that you could choose from to model the data and scikit-learn provides support for a number of <a href="https://scikit-learn.org/stable/user_guide.html">them</a>, as well as a <a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">chart</a> to help select the one that's right for your scenario. For now, use the <a href="https://scikit-learn.org/stable/modules/naive_bayes.html">Naïve Bayes algorithm</a>, a common algorithm for classification problems. Add a cell with the following code to create and train the algorithm.</p>
<pre><code class="lang-python">from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(X_train, y_train)
</code></pre>
</li>
<li><p>With a trained model, you can now try it against the test data set that was held back from training. Add and run the following code to predict the outcome of the test data and calculate the accuracy of the model.</p>
<pre><code class="lang-python">from sklearn import metrics
predict_test = model.predict(X_test)
print(metrics.accuracy_score(y_test, predict_test))
</code></pre>
<p><img src="images/data-science-tutorial/jupyter-cell-05.png" alt="Running the trained model against test data"></p>
<p>Looking at the result of the test data, you'll see that the trained algorithm had a ~75% success rate at estimating survival.</p>
</li>
</ol>
<h2 id="optional-use-a-neural-network-to-increase-accuracy">(Optional) Use a neural network to increase accuracy</h2>
<p>A neural network is a model that uses weights and activation functions, modeling aspects of human neurons, to determine an outcome based on provided inputs. Unlike the machine learning algorithm you looked at previously, neural networks are a form of deep learning wherein you don't need to know an ideal algorithm for your problem set ahead of time. It can be used for many different scenarios and classification is one of them. For this section, you'll use the <a href="https://keras.io/">Keras</a> library with <a href="https://www.tensorflow.org/">TensorFlow</a> to construct the neural network, and explore how it handles the Titanic dataset.</p>
<ol>
<li><p>The first step is to import the required libraries and to create the model. In this case, you'll use a <a href="https://keras.io/getting-started/sequential-model-guide/">Sequential</a> neural network, which is a layered neural network wherein there are multiple layers that feed into each other in sequence.</p>
<pre><code class="lang-python">from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
</code></pre>
</li>
<li><p>After defining the model, the next step is to add the layers of the neural network. For now, let's keep things simple and just use three layers. Add the following code to create the layers of the neural network.</p>
<pre><code class="lang-python">model.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 5))
model.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu'))
model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))
</code></pre>
<ul>
<li>The first layer will be set to have a dimension of 5, since you have 5 inputs: sex, pclass, age, relatives, and fare.</li>
<li>The last layer must output 1, since you want a 1-dimensional output indicating whether a passenger would survive.</li>
<li>The middle layer was kept at 5 for simplicity, although that value could have been different.</li>
</ul>
<p>The rectified linear unit (relu) activation function is used as a good general activation function for the first two layers, while the sigmoid activation function is required for the final layer as the output you want (of whether a passenger survives or not) needs to be scaled in the range of 0-1 (the probability of a passenger surviving).</p>
<p>You can also look at the summary of the model you built with this line of code:</p>
<pre><code class="lang-python">model.summary()
</code></pre>
<p><img src="images/data-science-tutorial/jupyter-cell-06.png" alt="Viewing a summary of the sequential neural network"></p>
</li>
<li><p>Once the model is created, it needs to be compiled. As part of this, you need to define what type of optimizer will be used, how loss will be calculated, and what metric should be optimized for. Add the following code to build and train the model. You'll notice that after training the accuracy is ~80%.</p>
<blockquote>
<p><strong>Note</strong>: This step may take anywhere from a few seconds to a few minutes to run depending on your machine.</p>
</blockquote>
<pre><code class="lang-python">model.compile(optimizer=&quot;adam&quot;, loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, batch_size=32, epochs=50)
</code></pre>
<p><img src="images/data-science-tutorial/jupyter-cell-07.png" alt="Build and train the neural network"></p>
</li>
<li><p>With the model built and trained its now time to see how it performs against the test data.</p>
<pre><code class="lang-python">y_pred = model.predict_classes(X_test)
print(metrics.accuracy_score(y_test, y_pred))
</code></pre>
<p><img src="images/data-science-tutorial/jupyter-cell-08.png" alt="Evaluate the neural network"></p>
<p>Similar to the training, you'll notice that you were able to get close to 80% accuracy in predicting survival of passengers. This result was better than the 75% accuracy from the Naive Bayes Classifier tried previously.</p>
</li>
</ol>
<h2 id="next-steps">Next steps</h2>
<p>Now that you're familiar with the basics of performing machine learning within Visual Studio Code, here are some other Microsoft resources and tutorials to check out.</p>
<ul>
<li>Learn more about working with <a href="https://youtu.be/FSdIoJdSnig">Jupyter Notebooks in Visual Studio Code</a> (video).</li>
<li><a href="https://docs.microsoft.com/azure/machine-learning/service/how-to-vscode-tools">Get started with Azure Machine Learning for VS Code</a> to deploy and optimize your model using the power of Azure.</li>
<li>Find additional data to explore on <a href="https://azure.microsoft.com/services/open-datasets/">Azure Open Data Sets</a>.</li>
</ul>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
                <h5>In This Article</h5>
                <div></div>
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            &#0169; 2021 Jason Rose
            
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../../../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../../../styles/docfx.js"></script>
    <script type="text/javascript" src="../../../styles/main.js"></script>
  </body>
</html>
